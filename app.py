import operator
import asyncio
import uuid
from typing import TypedDict, Annotated, List
from functools import partial

from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.prompt import Prompt

import os
import logging
from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage, AIMessage, get_buffer_string
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, START, END
from langgraph.errors import GraphRecursionError
from langchain_core.tools import tool
from langgraph.types import Command

from langchain.chat_models import init_chat_model
from langchain_core.rate_limiters import InMemoryRateLimiter
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_mcp_adapters.tools import load_mcp_tools
from dotenv import load_dotenv

from src.prompts import command_prompt
from src.web_automation_planning import clarify_with_user, planning_automation, human_approval
from src.state_automation import AgentState
import json 

load_dotenv()
logging.basicConfig(level=logging.ERROR)

# --- 1. ì´ˆê¸° ì„¤ì • ---
console = Console()
STATE_FILE = "agent_state.json"

mcp_config = {
    "playwright": {
        "command": "npx",
        "args": [
            "-y",
            "@playwright/mcp@latest",
            # "--user-data-dir=./browser_data",  # ğŸ‘ˆ ì„¸ì…˜ ìœ ì§€
            # "--save-session"                  # ğŸ‘ˆ ì„¸ì…˜ ì €ì¥
        ],
        "transport": "stdio"
    }
}

_client = None

async def get_mcp_client() -> MultiServerMCPClient:
    """
    ì „ì—­ MCP Client ìƒì„± ë° ì¬ì‚¬ìš©.
    ìµœì´ˆ ì‹¤í–‰ ì‹œì—ë§Œ ì„œë²„ë¥¼ ë„ìš°ê³ , ì´í›„ì—ëŠ” ê°™ì€ ì„¸ì…˜ì„ ì¬ì‚¬ìš©.
    """
    global _client
    if _client is None:
        console.print(Panel("[bold yellow]Creating MCP client...[/bold yellow]", expand=False))
        _client = MultiServerMCPClient(mcp_config)
        console.print("[green]âœ“ MCP client started successfully![/green]")
    return _client

@tool(parse_docstring=True)
def finish_step(reason: str) -> str:
    """
    Call this tool to signal that the current step of the plan is complete.
    Args:
        reason: A brief explanation of why you believe the step is complete.
    Returns:
        A confirmation that the step has been marked as complete.
    """
    return f"Step marked as complete. Reason: {reason}"

# @tool(parse_docstring=True)
# def think_tool(reflection: str, current_plan_step: int) -> str:
#     """
#     Tool for strategically reflecting on the progress of a web automation task and deciding the next action.

#     Args:
#         reflection: Your detailed thoughts on the webpage state, task progress, obstacles, and the next action plan.
#                     You should structure your reflection to include your observation, analysis, and a proposed next step.
#         current_plan_step: The index (0-based) of the current step in the plan you are working on.
    
#     Returns:
#         A confirmation that the reflection has been recorded to inform the next decision.
#     """
#     console.print(Panel(f"[bold yellow]ğŸ¤” Agent's Reflection:[/bold yellow]\n{reflection}", border_style="yellow"))
#     return f"Reflection recorded. Currently on plan step {current_plan_step}."

@tool(parse_docstring=True)
def extracted_data_tool(data_to_extract: dict) -> str:
    """
    Extracts and stores key-value data into the agent's state.

    For example:
    {"flight_price": "$500", "departure_time": "10:00 AM"}

    Args:
        data_to_extract (dict): A dictionary containing the data to be stored.
    
    Returns:
        A confirmation message indicating that the data has been stored.
    """
    console.print(Panel(f"[bold green]ğŸ“Š Storing data:[/bold green]\n{json.dumps(data_to_extract, indent=2)}", border_style="green"))
    # The actual data storage will be handled by updating the AgentState,
    # so we just return a success message here.
    # The dictionary will be directly updated into the 'extracted_data' field.
    return "Data has been successfully stored in the agent's state."

# --- 3. íˆ´ ì„¸íŒ… ---
async def setup_tools():
    client = await get_mcp_client()
    console.print(Panel("[bold yellow]Getting tools....[/bold yellow]", expand=False))
    mcp_tools = await client.get_tools()   # ë™ì¼ ì„¸ì…˜ì—ì„œ íˆ´ ë¡œë“œ
    # all_tools = mcp_tools + [think_tool, extracted_data_tool]
    all_tools = mcp_tools + [extracted_data_tool, finish_step]
    return all_tools

def show_tools_table(all_tools) -> List:
    table = Table(title="Available Agent Tools", show_header=True, header_style="bold magenta")
    table.add_column("Tool Name", style="cyan", width=25)
    table.add_column("Description", style="white", width=80)
    for t in all_tools:
        description = t.description[:77] + "..." if len(t.description) > 80 else t.description
        table.add_row(t.name, description)
    console.print(table)
    console.print(f"[bold green]âœ“ Successfully retrieved {len(all_tools)} tools[/bold green]")

# --- ìƒíƒœ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° í—¬í¼ í•¨ìˆ˜ ---
# app.py - ìˆ˜ì •ëœ ì½”ë“œ

def save_agent_state(state: AgentState, filename: str = "agent_state.json"):
    """
    AgentState ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    try:
        serializable_state = {
            "task": state.get("task"),
            "messages": [m.model_dump() for m in state.get("messages", [])],
            "plan": state.get("plan"),
            "current_plan_step": state.get("current_plan_step"),
            "action_history": state.get("action_history"),
            "last_error": state.get("last_error"),
            "extracted_data": state.get("extracted_data"),
            "final_answer": state.get("final_answer"),
            "workflow_summary": state.get("workflow_summary"),
            "max_messages_for_agent": state.get("max_messages_for_agent", 5),
            # --- ì´ ì¤„ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤! ---
            "last_snapshot": state.get("last_snapshot")
        }
        with open(filename, "w", encoding='utf-8') as f:
            json.dump(serializable_state, f, indent=4, ensure_ascii=False)
    except TypeError as e:
        print(f"Error saving state: {e}")

def load_agent_state() -> AgentState or None:
    """JSON íŒŒì¼ì—ì„œ AgentStateë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°"""
    if not os.path.exists(STATE_FILE):
        return None
    try:
        with open(STATE_FILE, "r", encoding='utf-8') as f:
            loaded_data = json.load(f)

            messages = []
            for msg_data in loaded_data.get("messages", []):
                msg_type = msg_data.get("type")
                if msg_type == "human":
                    messages.append(HumanMessage(**msg_data))
                elif msg_type == "ai":
                    messages.append(AIMessage(**msg_data))
                elif msg_type == "tool":
                    messages.append(ToolMessage(**msg_data))
                elif msg_type == "system":
                    messages.append(SystemMessage(**msg_data))

            loaded_data["messages"] = messages
    
            console.print(Panel("[bold green]âœ“ ì´ì „ ì‘ì—… ìƒíƒœë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.[/bold green]", border_style="green"))
            return loaded_data
    except Exception as e:
        console.print(Panel(f"[bold red]Error loading state: {e}. ìƒˆ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.[/bold red]", border_style="red"))
        return None
    
# Add this function to app.py
def summarize_agent_state(state: AgentState) -> str:
    """
    Generates a user-facing summary of the agent's current state.
    """
    summary = "Here is a summary of the task's progress so far:\n\n"

    task = state.get("task", "N/A")
    summary += f"**Task:** {task}\n\n"
    # 1. Summarize the plan
    plan_steps = state.get("plan", [])
    if plan_steps:
        summary += "**Current Plan:**\n"
        for i, step in enumerate(plan_steps):
            summary += f"- {step}\n"
    else:
        summary += "**Current Plan:** None\n"

    # 2. Summarize the action history (showing only the last 5 actions for clarity)
    action_history = state.get("action_history", [])
    if action_history:
        summary += "\n**Recent Web Interaction History:**\n"
        for action in action_history[-5:]:
            summary += f"- {action}\n"
    else:
        summary += "\n**Web Interaction History:** None\n"
    
    # 3. Summarize the extracted data
    extracted_data = state.get("extracted_data", {})
    if extracted_data:
        summary += "\n**Information Found So Far:**\n"
        for key, value in extracted_data.items():
            summary += f"- {key}: {value}\n"
    else:
        summary += "\n**Information Found So Far:** None\n"

    return summary

# --- 2. ë„êµ¬ ì‹¤í–‰ê¸° ì •ì˜ ---
class ToolExecutor:
    def __init__(self, tools: List):
        self.tools_by_name = {tool.name: tool for tool in tools}

    async def __call__(self, tool_call: dict, config=None):
        tool_name = tool_call["name"]
        tool_args = tool_call["args"]
        console.print(Panel(f"[bold blue]ğŸ› ï¸ Executing Tool: `{tool_name}`[/bold blue]\nArguments: {tool_args}", border_style="blue"))
        if tool_name == "think_tool":
            result = self.tools_by_name[tool_name].invoke(tool_args)
            return result, tool_args.get("current_plan_step", 0)
        else:
            result = await self.tools_by_name[tool_name].ainvoke(tool_args)
            return result, None


# --- 4. LangGraph ì›Œí¬í”Œë¡œìš° ì •ì˜ ---
# class AgentState(TypedDict): 
#     messages: Annotated[list[AnyMessage], operator.add]


# app.py

async def agent_node(state: AgentState, model_with_tools):
    plan = state.get("plan", [])
    step_index = state.get("current_plan_step", 0)
    if plan and step_index < len(plan):
        console.print(
            Panel(
                f"Current Step ({step_index + 1}/{len(plan)}): [bold cyan]{plan[step_index]}[/bold cyan]",
                title="ğŸš€ Executing Plan",
                border_style="cyan"
            )
        )
    guidance = (
        "You are a web automation expert. Your goal is to execute a multi-step plan.\n"
        "Analyze the user's request and the current page snapshot to determine the single best tool call to make progress on the current plan step.\n\n"
        "## Current Plan\n"
        "- Current step index (0-based): {step_index}\n"
        "- Current step description: {step_description}\n"
        "- Full plan for reference:\n{full_plan}\n\n"
        "## Constraints\n"
        "1. **FOCUS ON ONE STEP**: Only execute actions for the CURRENT step. Do not move to the next step prematurely.\n"
        "2. **ANALYZE and ACT**: After observing a `browser_snapshot`, you MUST call an action tool (e.g., `browser_click`, `extracted_data_tool`) to interact with the page or extract information. Do not call `browser_snapshot` again without acting first.\n"
        "3. **FINISH THE STEP**: Once you believe the deliverable for the current step is complete, you MUST call the `finish_step` tool to move to the next plan step."
    ).format(
        step_index=int(step_index),
        step_description=plan[step_index] if plan and step_index < len(plan) else "N/A",
        full_plan="\n".join([f"  - {i+1}. {s}" for i, s in enumerate(plan)])
    )

    # í† í° ì´ìŠˆ ëŒ€ì‘: ì ì§„ì  ë©”ì‹œì§€ ì¶•ì†Œ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    max_messages = state.get("max_messages_for_agent", 5)
    messages = state.get('messages', [])
    last_msg = messages[-1] if messages else None
    if (last_msg and hasattr(last_msg, 'response_metadata') and
        last_msg.response_metadata and
        last_msg.response_metadata.get('finish_reason') == 'MAX_TOKENS'):
        max_messages = max(1, max_messages - 1)
        console.print(Panel(f"[bold yellow]ğŸ”§ Reducing context to {max_messages} messages due to MAX_TOKENS[/bold yellow]", border_style="yellow"))

    recently_executed = []
    recent_messages = messages[-max_messages:]

    for i, msg in enumerate(recent_messages):
        is_last_message = (i == len(recent_messages) - 1)
        if msg.type == 'human':
            recently_executed.append(f"Human : {msg.content}")
        elif msg.type == 'ai':
            if msg.tool_calls:
                recently_executed.append(f"AI(tool) : {msg.content} / Tool Usage : {[f'{tool_call['name']} ({tool_call['args']})' for tool_call in msg.tool_calls]}")
            else:
                recently_executed.append(f"AI : {msg.content}")
        elif msg.type == 'system':
            recently_executed.append(f"System : {msg.content}")
        elif msg.type == 'tool':
            if not is_last_message and len(msg.content) > 1000:
                continue
            recently_executed.append(f"Tool Output : {msg.content}")

    recent_history = "Below is the recent history:\n\n" + "\n".join(recently_executed)

    # === ìŠ¤ëƒ…ìƒ· ì£¼ì… ë° ì†Œë¹„ ë¡œì§ ===
    last_snapshot = state.get("last_snapshot")
    if last_snapshot:
        console.print(Panel("[bold cyan]Injecting snapshot into context for this turn...[/bold cyan]", border_style="cyan"))
        recent_history += f"\n\nHere is the current browser snapshot for your analysis:\n<snapshot>\n{last_snapshot}\n</snapshot>"

    model_input_messages = [
        SystemMessage(content=guidance),
        SystemMessage(content=command_prompt),
        HumanMessage(content=recent_history)
    ]

    response = await model_with_tools.ainvoke(model_input_messages)

    # === ë°˜í™˜ ê°’ì— last_snapshot ì´ˆê¸°í™” ì¶”ê°€ ===
    updates_to_return = {"messages": [response]}
    if last_snapshot:
        updates_to_return["last_snapshot"] = None

    # MAX_TOKENS ì´ìŠˆ ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    if (hasattr(response, 'response_metadata') and
        response.response_metadata and
        response.response_metadata.get('finish_reason') == 'MAX_TOKENS'):
        console.print(Panel(f"[bold red]âš ï¸ MAX_TOKENS detected, will reduce context further next time[/bold red]", border_style="red"))
        updates_to_return["max_messages_for_agent"] = max_messages
        return updates_to_return

    # ì„±ê³µ ì‹œ ë©”ì‹œì§€ ìˆ˜ ë³µêµ¬ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    if max_messages < 5:
        console.print(Panel(f"[bold green]âœ… Response successful, resetting context to 5 messages[/bold green]", border_style="green"))
        updates_to_return["max_messages_for_agent"] = 5

    return updates_to_return


async def tool_node(state: AgentState, tool_executor: ToolExecutor):
    """
    ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ê³  browser_snapshot, extracted_data_toolê³¼ ê°™ì€
    íŠ¹ìˆ˜ ë„êµ¬ì˜ ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    tool_calls = state["messages"][-1].tool_calls
    tool_messages = []
    last_error = None
    current_plan_step = state.get("current_plan_step", 0)

    # ì´ ë…¸ë“œì—ì„œ ë°œìƒí•œ ëª¨ë“  ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ ë‹´ì„ ë”•ì…”ë„ˆë¦¬
    state_updates = {}

    for tool_call in tool_calls:
        tool_name = tool_call["name"]
        try:
            if tool_call["name"] == "finish_step":
                current_plan_step += 1 # í˜„ì¬ ë‹¨ê³„ë¥¼ 1 ì¦ê°€ì‹œí‚´
                output = "Step finished. Moving to the next step."
            else:
                # ê¸°ì¡´ tool_executor í˜¸ì¶œ (new_step ë°˜í™˜ ê°’ì€ ì‚¬ìš© ì•ˆí•¨)
                output, _ = await tool_executor(tool_call)

                if tool_name == "browser_snapshot":
                    # 1. ìƒíƒœì˜ 'last_snapshot' í•„ë“œë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
                    state_updates["last_snapshot"] = str(output)
                    # 2. ê±°ëŒ€í•œ ìŠ¤ëƒ…ìƒ· ë‚´ìš© ëŒ€ì‹  í™•ì¸ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
                    tool_messages.append(
                        ToolMessage(content="ìŠ¤ëƒ…ìƒ·ì„ ì°ì–´ 'last_snapshot'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.", tool_call_id=tool_call["id"])
                    )
                elif tool_name == "extracted_data_tool":
                    # 1. ë„êµ¬ì˜ ì¸ìì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
                    data = tool_call["args"]["data_to_extract"]
                    # 2. ê¸°ì¡´ extracted_dataì™€ í•©ì¹©ë‹ˆë‹¤.
                    # LangGraphê°€ ì—…ë°ì´íŠ¸ë¥¼ ê°ì§€í•˜ë„ë¡ ìƒˆ ë”•ì…”ë„ˆë¦¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.
                    new_extracted_data = state.get("extracted_data", {}).copy()
                    new_extracted_data.update(data)
                    state_updates["extracted_data"] = new_extracted_data
                    # 3. ë„êµ¬ê°€ ì›ë˜ ë°˜í™˜í•˜ë˜ í™•ì¸ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
                    tool_messages.append(
                        ToolMessage(content=str(output), tool_call_id=tool_call["id"])
                    )
                else:
                    # ë‹¤ë¥¸ ëª¨ë“  ë„êµ¬ëŠ” ê·¸ëƒ¥ ê²°ê³¼ê°’ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
                    tool_messages.append(
                        ToolMessage(content=str(output), tool_call_id=tool_call["id"])
                    )

        except Exception as e:
            error_message = f"ë„êµ¬ {tool_name} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}"
            console.print(Panel(f"[bold red]{error_message}[/bold red]", border_style="red"))
            tool_messages.append(ToolMessage(content=error_message, tool_call_id=tool_call["id"]))
            last_error = error_message

    # ë°˜í™˜í•  ëª¨ë“  ì—…ë°ì´íŠ¸ë¥¼ í†µí•©í•©ë‹ˆë‹¤.
    final_updates = {
        "messages": tool_messages,
        "last_error": last_error,
        "current_plan_step": int(current_plan_step),
    }
    final_updates.update(state_updates) # ìŠ¤ëƒ…ìƒ· ë˜ëŠ” ì¶”ì¶œ ë°ì´í„° ì—…ë°ì´íŠ¸ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

    return final_updates

async def report_node(state: AgentState, model):
    """
    Generates a final report based on the executed plan and extracted data.
    """
    console.print(Panel("[bold magenta]ğŸ“Š Generating Report...[/bold magenta]", border_style="magenta"))

    # Prepare the context for the reporting model
    context = (
        f"Task: {state.get('task')}\n\n"
        f"Execution Plan:\n" + "\n".join([f"- {step}" for step in state.get('plan', [])]) + "\n\n"
        f"Extracted Data:\n{json.dumps(state.get('extracted_data', {}), indent=2)}\n\n"
        "Please generate a final answer for the user based on the above information. "
        "Also, provide a brief summary of the workflow."
    )

    response = await model.ainvoke([HumanMessage(content=context)])
    
    # For simplicity, we'll just use the content of the response.
    # In a more complex scenario, you might want to structure this output.
    final_answer = response.content
    workflow_summary = "The task was completed following the generated plan and the necessary data was extracted." # A simplified summary

    return {
        "final_answer": final_answer,
        "workflow_summary": workflow_summary
    }


def should_continue(state: AgentState):
    last_msg = state["messages"][-1]
    # 1) ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ê°€ ë„êµ¬ í˜¸ì¶œì„ í¬í•¨í•˜ë©´ toolsë¡œ ì´ë™
    if getattr(last_msg, "tool_calls", None):
        return "tools"
    
    # 2) ëª¨ë“  ê³„íšì´ ì™„ë£Œë˜ì—ˆìœ¼ë©´ ì¢…ë£Œ (report ë…¸ë“œë¡œ ì´ë™)
    plan = state.get("plan", [])
    current_step = int(state.get("current_plan_step", 0) or 0)
    if not plan or current_step >= len(plan):
        return "end"
    
    # 3) ì•„ì§ ê³„íšì´ ë‚¨ì•„ìˆë‹¤ë©´ agentë¡œ ë‹¤ì‹œ ë£¨í”„
    return "agent"

def get_command_destination(node_result) -> str:
    # node_resultëŠ” ë…¸ë“œì˜ ë°˜í™˜ê°’ì´ë©°, Commandì¼ ê²½ìš° í•´ë‹¹ gotoë¡œ ë¼ìš°íŒ…
    if isinstance(node_result, Command):
        return node_result.goto
    return "end"

# --- 7. ë©”ì¸ ì‹¤í–‰ ---
async def main():

    client = await get_mcp_client()
    async with client.session("playwright") as session:
        mcp_tools = await load_mcp_tools(session)
        # all_tools = mcp_tools + [think_tool, extracted_data_tool]
        all_tools = mcp_tools + [extracted_data_tool, finish_step]
        # all_tools = mcp_tools
        # all_tools = await setup_tools()
        show_tools_table(all_tools)
        tool_executor = ToolExecutor(all_tools)

        rate_limiter = InMemoryRateLimiter(
            requests_per_second=0.25,
            check_every_n_seconds=0.1,
            max_bucket_size=5
        )
        console.print(Panel("[bold cyan]Rate limiter configured (~1 request / 4 sec)[/bold cyan]"))

        model = init_chat_model(
            model="google_genai:gemini-2.0-flash-lite",
            rate_limiter=rate_limiter,
            temperature=0
        )
        model_with_tools = model.bind_tools(all_tools)

        workflow = StateGraph(AgentState)
        workflow.add_node("clarify_with_user", clarify_with_user)
        workflow.add_node("planning_automation", planning_automation)
        workflow.add_node("human_approval", human_approval)
        workflow.add_node("agent", partial(agent_node, model_with_tools=model_with_tools))
        workflow.add_node("tools", partial(tool_node, tool_executor=tool_executor))
        workflow.add_node("report", partial(report_node, model=model))

        # workflow.add_edge(START, "clarify_with_user")
        workflow.set_entry_point("clarify_with_user")
        workflow.add_conditional_edges(
            "clarify_with_user",
            get_command_destination,
            {
                "clarify_with_user": "clarify_with_user",   
                "planning_automation": "planning_automation",
                "end" : END
            }
        )
        workflow.add_edge("planning_automation", "human_approval")

        workflow.add_conditional_edges(
            "human_approval",
            get_command_destination,
            {
                "agent" : "agent",
                "planning_automation": "planning_automation",
                "human_approval": "human_approval",
                "end": END
            }
        )

        workflow.add_conditional_edges(
            "agent", 
            should_continue, 
            {
                "tools": "tools",
                "agent": "agent",
                "end": "report"
            }
        )
        workflow.add_edge("tools", "agent")
        workflow.add_edge("report", END)
        app = workflow.compile()
        console.print(Panel("[bold green]Web Automation Agent is ready.[/bold green]", title="ğŸ¤– Agent Ready"))

        RESUME = False

        current_state = load_agent_state()

        if current_state:
            console.print(Panel("[bold]ì´ì „ ì‘ì—… ë‚´ìš©:[/bold]\n[dim]Task: {task}\nPlan: {plan}[/dim]".format(
                task=current_state.get('task', 'N/A'),
                plan='\n'.join(current_state.get('plan', []))
            ), title="Last Session"))
            resume = Prompt.ask("ì´ì „ ì‘ì—…ì„ ì´ì–´ì„œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?", choices=["yes", "no"], default="yes")
            if resume.lower() == "no":
                current_state = None
            else:
                RESUME = True
        if not current_state:
            current_state = {
                "messages" : [SystemMessage(content=command_prompt)],
                "action_history": [],
                "extracted_data": {},
                "current_plan_step": 0,
                "plan": [],
                "max_messages_for_agent": 5,
                "last_snapshot": None
            }

        while True:
            if not RESUME:
                console.print(Panel("[bold]Please enter your request (type 'exit' or 'quit' to stop):[/bold]", border_style="blue"))
                user_input = Prompt.ask("[bold]You[/bold]")
                if user_input.lower() in ["exit", "quit"]:
                    break
            else:
                user_input = None
                RESUME = False

            if user_input:
                if not current_state.get("task"):
                    current_state["task"] = user_input
                
                current_state['messages'].append(
                    HumanMessage(content = user_input)
                )

            try:
                async for event in app.astream(current_state, {"recursion_limit": 20}):
                    # ê° ë…¸ë“œì—ì„œ ë°˜í™˜ëœ ì—…ë°ì´íŠ¸ë¥¼ current_stateì— ë³‘í•©
                    for _, node_update in event.items():
                        if not isinstance(node_update, dict):
                            continue
                        for field_name, field_value in node_update.items():
                            if field_name == "messages" and isinstance(field_value, list):
                                current_state.setdefault("messages", []).extend(field_value)
                            elif field_name == "action_history" and isinstance(field_value, list):
                                current_state.setdefault("action_history", []).extend(field_value)
                            elif field_name == "extracted_data" and isinstance(field_value, dict):
                                current_state.setdefault("extracted_data", {}).update(field_value)
                            else:
                                current_state[field_name] = field_value

                    # ì´ë²¤íŠ¸ ë³‘í•© í›„ ì €ì¥
                    save_agent_state(current_state)

                # ë§ˆì§€ë§‰ ì‘ë‹µ ì„ íƒ: ê°€ì¥ ìµœê·¼ AI ë©”ì‹œì§€ ìš°ì„ , ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ë©”ì‹œì§€
                final_msg = None
                for msg in reversed(current_state["messages"]):
                    if isinstance(msg, AIMessage):
                        final_msg = msg
                        break
                if final_msg is None and current_state["messages"]:
                    final_msg = current_state["messages"][-1]

                if final_msg and getattr(final_msg, "content", None):
                    console.print(Panel(f"[bold green]ğŸ¤– Agent:[/bold green]\n{final_msg.content}", border_style="green"))
            
            except GraphRecursionError as e:
                console.print(
                    Panel(f"[bold red]âŒ I'm sorry. The task was interrupted because the recursion limit was reached.[/bold red]", border_style="red")
                )
                # Generate a summary of the current state for the user
                summary = summarize_agent_state(current_state)
                
                final_response = model.invoke(
                    [
                        SystemMessage(
                            content=f"""
                            You are an AI assistant specialized in completing user tasks. A technical error has interrupted the current task, and you cannot proceed. Your new objective is to inform the user about this issue in a clear, helpful, and transparent manner.

                                Your response MUST follow these steps:
                                1.  **Acknowledge the Interruption:** Start by politely informing the user that the task could not be fully completed due to a technical issue. Be friendly and apologetic.
                                2.  **Report Progress:** Based on the provided summary of the agent's state, detail what has been successfully accomplished so far. Specifically, extract and highlight any final, actionable information that was found. For example, if the task was to find a movie to book, clearly state the movie title, showtime, and any other relevant details that were successfully retrieved.
                                3.  **Explain the Point of Failure:** Briefly and in plain language, explain where the process was interrupted (e.g., "ì˜í™”ë¥¼ ì°¾ëŠ” ë°ëŠ” ì„±ê³µí–ˆì§€ë§Œ, ì˜ˆì•½ ê³¼ì •ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤" or "ì›í•˜ì‹œëŠ” ì •ë³´ë¥¼ ì°¾ì•˜ìœ¼ë‚˜, ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤").
                                4.  **Offer Next Steps:** End by apologizing for the inconvenience and offering to assist with a new task. Your goal is to provide a complete, standalone message that is helpful despite the failure.
                                5.  **Maintain a Friendly and Non-technical Tone:** Avoid jargon. Your entire response should be a single, coherent message to the user, not a list of raw data.
                                6.  **You Must answer in Korean.**
                            """
                        ), 
                        HumanMessage(
                            content=summary
                        )
                    ]
                )
                # Output the summary to the user
                console.print(Panel(f"[bold green]ğŸ¤– Agent:[/bold green]\n{final_response.content}", border_style="green"))

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        console.print("\n[bold red]Process interrupted by user. Exiting...[/bold red]")
